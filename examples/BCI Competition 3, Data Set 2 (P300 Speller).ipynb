{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Dataset\n",
    "\n",
    "This example uses the [Data Set 2][bcicomp3ds2] from the BCI Competition 3. After downloading and copying it into a directory called `data` next to this script, you should be able to follow this example.\n",
    "\n",
    "[bcicomp3ds2]: http://www.bbci.de/competition/iii/#data_set_ii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import ticker\n",
    "import matplotlib as mpl\n",
    "\n",
    "from wyrm import plot\n",
    "plot.beautify()\n",
    "from wyrm.types import Data\n",
    "from wyrm import processing as proc\n",
    "from wyrm.io import load_bcicomp3_ds2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_A = 'data/BCI_Comp_III_Wads_2004/Subject_A_Train.mat'\n",
    "TRAIN_B = 'data/BCI_Comp_III_Wads_2004/Subject_B_Train.mat'\n",
    "\n",
    "TEST_A = 'data/BCI_Comp_III_Wads_2004/Subject_A_Test.mat'\n",
    "TEST_B = 'data/BCI_Comp_III_Wads_2004/Subject_B_Test.mat'\n",
    "\n",
    "TRUE_LABELS_A = 'WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU'\n",
    "TRUE_LABELS_B = 'MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR'\n",
    "\n",
    "MATRIX = ['abcdef',\n",
    "          'ghijkl',\n",
    "          'mnopqr',\n",
    "          'stuvwx',\n",
    "          'yz1234',\n",
    "          '56789_']\n",
    "\n",
    "MARKER_DEF_TRAIN = {'target': ['target'], 'nontarget': ['nontarget']}\n",
    "MARKER_DEF_TEST = {'flashing': ['flashing']}\n",
    "\n",
    "SEG_IVAL = [0, 700]\n",
    "\n",
    "JUMPING_MEANS_IVALS_A = [150, 220], [200, 260], [310, 360], [550, 660] # 91%\n",
    "JUMPING_MEANS_IVALS_B = [150, 250], [200, 280], [280, 380], [480, 610] # 91%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing_simple(dat, MRK_DEF, *args, **kwargs):\n",
    "    \"\"\"Simple preprocessing that reaches 97% accuracy.\n",
    "    \"\"\"\n",
    "    fs_n = dat.fs / 2\n",
    "    b, a = proc.signal.butter(5, [10 / fs_n], btype='low')\n",
    "    dat = proc.filtfilt(dat, b, a)\n",
    "   \n",
    "    dat = proc.subsample(dat, 20)\n",
    "    epo = proc.segment_dat(dat, MRK_DEF, SEG_IVAL)\n",
    "    fv = proc.create_feature_vectors(epo)\n",
    "    return fv, epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessing(dat, MRK_DEF, JUMPING_MEANS_IVALS):\n",
    "    dat = proc.sort_channels(dat)\n",
    "    \n",
    "    fs_n = dat.fs / 2\n",
    "    b, a = proc.signal.butter(5, [30 / fs_n], btype='low')\n",
    "    dat = proc.lfilter(dat, b, a)\n",
    "    b, a = proc.signal.butter(5, [.4 / fs_n], btype='high')\n",
    "    dat = proc.lfilter(dat, b, a)\n",
    "    \n",
    "    dat = proc.subsample(dat, 60)\n",
    "    epo = proc.segment_dat(dat, MRK_DEF, SEG_IVAL)\n",
    "    \n",
    "    fv = proc.jumping_means(epo, JUMPING_MEANS_IVALS)\n",
    "    fv = proc.create_feature_vectors(fv)\n",
    "    return fv, epo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:wyrm.processing:Subsampling led to loss of 2 samples, in an online setting consider using a BlockBuffer with a buffer size of a multiple of 4 samples.\n",
      "WARNING:wyrm.processing:Subsampling led to loss of 2 samples, in an online setting consider using a BlockBuffer with a buffer size of a multiple of 4 samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Result for subject 1\n",
      "Constructed labels: WQXPLZCOMRKOW7YFZDEZ1DPI9NN2GRKDJCUJRMEUOCOJD2UFYPOO6J7LDGYEGOA5VHNEKBW4OO1TDOILUEE5BFAEEXAW_K3R3MRU\n",
      "True labels       : WQXPLZCOMRKO97YFZDEZ1DPI9NNVGRQDJCUVRMEUOOOJD2UFYPOO6J7LDGYEGOA5VHNEHBTXOO1TDOILUEE5BFAEEXAW_K4R3MRU\n",
      "Accuracy: 91.0%\n",
      "\n",
      "Result for subject 2\n",
      "Constructed labels: MERMIROOMUZJPXJOHUVFBORZP3GLOO7AUFDKEFTWEOOALZOP9R1CGZE11Y19EWX65QUYU7NAK_1ACJDVDNGQXOJBEV2B5EFDIDTR\n",
      "True labels       : MERMIROOMUHJPXJOHUVLEORZP3GLOO7AUFDKEFTWEOOALZOP9ROCGZET1Y19EWX65QUYU7NAK_4YCJDVDNGQXODBEV2B5EFDIDNR\n",
      "Accuracy: 91.0%\n",
      "\n",
      "Overal accuracy: 91.0%\n"
     ]
    }
   ],
   "source": [
    "epo = [None, None]\n",
    "acc = 0\n",
    "for subject in range(2):\n",
    "    if subject == 0:\n",
    "        training_set = TRAIN_A\n",
    "        testing_set = TEST_A\n",
    "        labels = TRUE_LABELS_A\n",
    "        jumping_means_ivals = JUMPING_MEANS_IVALS_A\n",
    "    else:\n",
    "        training_set = TRAIN_B\n",
    "        testing_set = TEST_B\n",
    "        labels = TRUE_LABELS_B\n",
    "        jumping_means_ivals = JUMPING_MEANS_IVALS_B\n",
    "    \n",
    "    # load the training set\n",
    "    dat = load_bcicomp3_ds2(training_set)\n",
    "    fv_train, epo[subject] = preprocessing(dat, MARKER_DEF_TRAIN, jumping_means_ivals)\n",
    "    \n",
    "    # train the lda\n",
    "    cfy = proc.lda_train(fv_train)\n",
    "    \n",
    "    # load the testing set\n",
    "    dat = load_bcicomp3_ds2(testing_set)\n",
    "    fv_test, _ = preprocessing(dat, MARKER_DEF_TEST, jumping_means_ivals)\n",
    "    \n",
    "    # predict\n",
    "    lda_out_prob = proc.lda_apply(fv_test, cfy)\n",
    "    \n",
    "    # unscramble the order of stimuli\n",
    "    unscramble_idx = fv_test.stimulus_code.reshape(100, 15, 12).argsort()\n",
    "    static_idx = np.indices(unscramble_idx.shape)\n",
    "    lda_out_prob = lda_out_prob.reshape(100, 15, 12)\n",
    "    lda_out_prob = lda_out_prob[static_idx[0], static_idx[1], unscramble_idx]\n",
    "    \n",
    "    #lda_out_prob = lda_out_prob[:, :5, :]\n",
    "    \n",
    "    # destil the result of the 15 runs\n",
    "    #lda_out_prob = lda_out_prob.prod(axis=1)\n",
    "    lda_out_prob = lda_out_prob.sum(axis=1)\n",
    "        \n",
    "    # \n",
    "    lda_out_prob = lda_out_prob.argsort()\n",
    "    \n",
    "    cols = lda_out_prob[lda_out_prob <= 5].reshape(100, -1)\n",
    "    rows = lda_out_prob[lda_out_prob > 5].reshape(100, -1)\n",
    "    text = ''\n",
    "    for i in range(100):\n",
    "        row = rows[i][-1]-6\n",
    "        col = cols[i][-1]\n",
    "        letter = MATRIX[row][col]\n",
    "        text += letter\n",
    "    print\n",
    "    print 'Result for subject %d' % (subject+1)\n",
    "    print 'Constructed labels: %s' % text.upper()\n",
    "    print 'True labels       : %s' % labels\n",
    "    a = np.array(list(text.upper()))\n",
    "    b = np.array(list(labels))\n",
    "    accuracy = np.count_nonzero(a == b) / len(a)\n",
    "    print 'Accuracy: %.1f%%' % (accuracy * 100)\n",
    "    acc += accuracy\n",
    "print\n",
    "print 'Overal accuracy: %.1f%%' % (100 * acc / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the data\n",
    "\n",
    "The following part shows how to visualize interesting information of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "avgs = [None, None]\n",
    "fig, axes = plt.subplots(2, 3, sharex=True, sharey=True, figsize=(9, 6))\n",
    "for idx, file in enumerate([TRAIN_A, TRAIN_B]):\n",
    "    avgs[idx] = proc.calculate_classwise_average(epo[idx])\n",
    "    #avgs[idx] = proc.correct_for_baseline(avgs[idx], [0, 50])\n",
    "    \n",
    "    d = proc.select_channels(avgs[idx], [\"fcz\", \"cz\", \"oz\"])\n",
    "    for i in range(3):\n",
    "        axes[idx, i].plot(d.axes[-2], d.data[..., i].T)\n",
    "        axes[idx, i].grid()\n",
    "\n",
    "for i in range(3):        \n",
    "    axes[0, i].set_title(d.axes[-1][i])\n",
    "    \n",
    "axes[1, 1].set_xlabel('time [ms]')\n",
    "for i in range(2):\n",
    "    axes[i, 0].set_ylabel(u'voltage [a.u.]')\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i, 2].yaxis.set_label_position(\"right\")\n",
    "    axes[i, 2].set_ylabel('Subject %s' % 'AB'[i])\n",
    "\n",
    "axes[0, -1].legend(d.class_names)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_scalps(epo, ivals):\n",
    "    # ratio scalp to colorbar width\n",
    "    scale = 10\n",
    "    dat = proc.jumping_means(epo, ivals)\n",
    "    n_classes = epo.data.shape[0]\n",
    "    n_ivals = len(ivals)\n",
    "    for class_idx in range(n_classes):\n",
    "        vmax = np.abs(dat.data).max()\n",
    "        vmax = round(vmax)\n",
    "        vmin = -vmax\n",
    "        for ival_idx in range(n_ivals):\n",
    "            ax = plt.subplot2grid((n_classes, scale*n_ivals+1), (class_idx, scale*ival_idx), colspan=scale)\n",
    "            plot.ax_scalp(dat.data[class_idx, ival_idx, :], epo.axes[-1], vmin=vmin, vmax=vmax)\n",
    "            if class_idx == 1:\n",
    "                ax.text(0, -1.5, ivals[ival_idx], horizontalalignment='center')\n",
    "            if ival_idx == 0:\n",
    "                ax.text(-1.5, 0, ['nontarget', 'target'][class_idx], color='bm'[class_idx], rotation='vertical', verticalalignment='center')\n",
    "    \n",
    "    # colorbar\n",
    "    ax = plt.subplot2grid((n_classes, scale*n_ivals+1), (0, scale*n_ivals), rowspan=n_classes)\n",
    "    plot.ax_colorbar(vmin, vmax, label='voltage [a.u.]', ticks=[vmin, 0, vmax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for subj_idx in range(2):\n",
    "    fig = plt.figure(figsize=(11, 6))\n",
    "    ivals = [JUMPING_MEANS_IVALS_A, JUMPING_MEANS_IVALS_B][subj_idx]\n",
    "    plot_scalps(avgs[subj_idx], ivals)\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(left=.06, bottom=.10, right=None, top=None, wspace=0, hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, sharex=True, sharey=True)\n",
    "for i in range(2):\n",
    "    r2 = proc.calculate_signed_r_square(epo[i])\n",
    "    # switch the sign to make the plot more consistent with the timecourse. This is equivalent to reordering the classidices and calculating r2\n",
    "    r2 *= -1\n",
    "    \n",
    "    max = np.max(np.abs(r2))\n",
    "    im = axes[i].imshow(r2.T, aspect='auto', interpolation='None', vmin=-max, vmax=max)\n",
    "    \n",
    "    axes[i].set_ylabel('%s' % (epo[i].names[-1]))\n",
    "    axes[i].grid()\n",
    "    axes[i].set_title(\"Subject %s\" % \"AB\"[i])\n",
    "    cb = plt.colorbar(im, ax=axes[i])\n",
    "    cb.set_label('[a.u.]')\n",
    "\n",
    "axes[1].yaxis.set_major_formatter(ticker.IndexFormatter(epo[i].axes[-1]))\n",
    "mask = map(lambda x: True if x.lower().endswith('z') else False, epo[i].axes[-1])\n",
    "axes[1].yaxis.set_major_locator(ticker.FixedLocator(np.nonzero(mask)[0]))\n",
    "axes[1].xaxis.set_major_formatter(ticker.IndexFormatter(['%d' % j for j in epo[i].axes[-2]]))\n",
    "axes[1].xaxis.set_major_locator(ticker.MultipleLocator(6))\n",
    "axes[1].set_xlabel('%s [%s]' % (epo[i].names[-2], epo[i].units[-2]))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
